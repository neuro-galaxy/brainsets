######################################################
# Perich & Miller (2018) 
######################################################

DATASET = "perich_miller_population_2018"
DANDI_ID = "000688"

RAW_DIR = Path(config["RAW_DIR"]) / DATASET
PROCESSED_DIR = Path(config["PROCESSED_DIR"]) / DATASET
PIPELINE_DIR = config["PIPELINE_DIR"]


checkpoint perich_miller_population_2018_download_data:
    output:
        f"{RAW_DIR}/manifest.txt"
    shell:
        f"""
        mkdir -p {RAW_DIR}
        dandi download -o {RAW_DIR} -e refresh DANDI:000688/draft
        find {RAW_DIR}/ -type f -name "*.nwb" | sed "s|^{RAW_DIR}/||" | sed "s|^/*||" > {{output}}
        """

rule prepare_data:
    input:
        nwb_file = f"{RAW_DIR}/{{file}}"
    output:
        temp(f"{PROCESSED_DIR}/tmp/{{file}}.txt")
    log:
        f".snakemake/logs/{DATASET}/prepare_data.{{file}}.log"
    shell:
        f"""
        mkdir -p {PROCESSED_DIR}/tmp
        python {PIPELINE_DIR}/prepare_data.py --input_file {{input.nwb_file}} --output_dir {PROCESSED_DIR}/{DATASET} >> {{log}}
        find {PROCESSED_DIR}/ -type f -name "*.h5" | sed "s|^{PROCESSED_DIR}/||" > {{output}}
        """

def aggregate_input(wildcards):
    with checkpoints.perich_miller_population_2018_download_data.get(**wildcards).output[0].open() as manifest:
        files = [line.strip() for line in manifest]
    return expand(f"{PROCESSED_DIR}/tmp/{{file}}.txt", file=files)

rule merge_manifests:
    input:
        aggregate_input
    output:
        f"{PROCESSED_DIR}/manifest.txt"
    shell:
        f"""
        find {PROCESSED_DIR}/ -type f -name "*.h5" | sed "s|^{PROCESSED_DIR}/||" > {{output}}        
        """

rule all:
    input:
        f"{PROCESSED_DIR}/manifest.txt"


# include: "../freeze.smk"

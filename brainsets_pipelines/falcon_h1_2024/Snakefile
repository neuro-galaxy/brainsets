######################################################
# Karpowicz & Ye et al. (2024)
# FALCON H1 (Human 7-DoF Arm Control)
#
# Default: Bins spikes at 20ms (FALCON benchmark standard)
# To preserve spike times: Edit BIN_SIZE_MS = None on line 15
######################################################

DATASET = "falcon_h1_2024"
DANDI_ID = "000954"

RAW_DIR = config["RAW_DIR"]
PROCESSED_DIR = config["PROCESSED_DIR"]

# Binning configuration for FALCON benchmark
# FALCON standard: 20ms bins
# To use unbinned spike times: set BIN_SIZE_MS = None and re-run
BIN_SIZE_MS = None

checkpoint falcon_h1_download_data:
    output:
        f"{RAW_DIR}/{DATASET}/manifest.txt"
    shell:
        f"""
        mkdir -p {RAW_DIR}/{DATASET}
        dandi download --existing skip -o {RAW_DIR}/{DATASET} DANDI:{DANDI_ID}
        find {RAW_DIR}/{DATASET}/ -type f -name "*.nwb" | sed "s|^{RAW_DIR}/{DATASET}/||" | sed "s|^/*||" > {{output}}
        """

rule prepare_data:
    input:
        nwb_file = f"{RAW_DIR}/{DATASET}/{{file}}"
    output:
        temp(f"{PROCESSED_DIR}/{DATASET}/tmp/{{file}}.txt")
    log:
        f".snakemake/logs/{DATASET}/prepare_data.{{file}}.log"
    params:
        bin_flag = f"--bin-size-ms {BIN_SIZE_MS}" if BIN_SIZE_MS is not None else "",
        bin_info = f"{BIN_SIZE_MS}ms bins" if BIN_SIZE_MS is not None else "spike times (unbinned)"
    shell:
        f"""
        echo "Processing with {{params.bin_info}}"
        mkdir -p {PROCESSED_DIR}/{DATASET}/tmp
        python -m brainsets_pipelines.{DATASET}.prepare_data --input_file {{input.nwb_file}} --output_dir {PROCESSED_DIR}/{DATASET} {{params.bin_flag}} >> {{log}}
        find {PROCESSED_DIR}/{DATASET}/ -type f -name "*.h5" | sed "s|^{PROCESSED_DIR}/{DATASET}//||" > {{output}}
        """

def aggregate_input(wildcards):
    with checkpoints.falcon_h1_download_data.get(**wildcards).output[0].open() as manifest:
        files = [line.strip() for line in manifest]
    return expand(f"{PROCESSED_DIR}/{DATASET}/tmp/{{file}}.txt", file=files)

rule merge_manifests:
    input:
        aggregate_input
    output:
        f"{PROCESSED_DIR}/{DATASET}/manifest.txt"
    shell:
        f"""
        find {PROCESSED_DIR}/{DATASET}/ -type f -name "*.h5" | sed "s|^{PROCESSED_DIR}/{DATASET}//||" > {{output}}
        """

rule all:
    input:
        f"{PROCESSED_DIR}/{DATASET}/manifest.txt"
